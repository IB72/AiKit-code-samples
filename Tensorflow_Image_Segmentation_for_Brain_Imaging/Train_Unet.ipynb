{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomedical Image Segmentation with U-Net\n",
    "\n",
    "In this code example, we apply the U-Net architecture to segment brain tumors from raw MRI scans as shown below. With relatively little data we are able to train a U-Net model to accurately predict where tumors exist. \n",
    "\n",
    "The Dice coefficient (the standard metric for the BraTS dataset used in the study) for this dataset on Unet model is about 0.82-0.88 on the large BraTs dataset.  Menze et al. [reported](http://ieeexplore.ieee.org/document/6975210/) that expert neuroradiologists manually segmented these tumors with a cross-rater Dice score of 0.75-0.85, meaning that the model’s predictions are on par with what expert physicians have made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/figure1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since its introduction two years ago, the [U-Net](https://arxiv.org/pdf/1505.04597.pdf0) architecture has been used to create deep learning models for segmenting [nerves](https://github.com/jocicmarko/ultrasound-nerve-segmentation) in ultrasound images, [lungs](https://www.kaggle.com/c/data-science-bowl-2017#tutorial) in CT scans, and even [interference](https://github.com/jakeret/tf_unet) in radio telescopes.\n",
    "\n",
    "## What is U-Net?\n",
    "U-Net is designed like an [auto-encoder](https://en.wikipedia.org/wiki/Autoencoder). It has an encoding path (“contracting”) paired with a decoding path (“expanding”) which gives it the “U” shape.  However, in contrast to the autoencoder, U-Net predicts a pixelwise segmentation map of the input image rather than classifying the input image as a whole. For each pixel in the original image, it asks the question: “To which class does this pixel belong?” This flexibility allows U-Net to predict different parts of the tumor simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/unet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module loads the data from `data.py`, creates a TensorFlow/Keras model from `model.py`, trains the model on the data, and then saves the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import settings    # Use the custom settings.py file for default parameters\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "# from model import load_model, get_callbacks, evaluate_model\n",
    "from data import load_data\n",
    "from model import unet\n",
    "\n",
    "from argparser import args\n",
    "\n",
    "if args.keras_api:\n",
    "    import keras as K\n",
    "else:\n",
    "    from tensorflow import keras as K\n",
    "\n",
    "onnx = False # Set whether we are exporting to ONNX model and using nGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For best CPU speed, Tune the number of intra and inter threads to take advantage of multi-core systems base don your hardware. Besides these settings, other important parameters are OMP_NUM_THREADS, KMP_BLOCKTIME, KMP_AFFINITY,KMP_SETTINGS that can set as environment variables. Refer the article [Maximize TensorFlow* Performance on CPU](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference) to learn more about these parameters. Set the OMP_NUM_THREADS and intra_op_parallelism_threads to number of physical cores in your processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]= \"56\"# <Tune this to get best performance anywhere from 1 to # of physical cores>\n",
    "args.num_threads=2\n",
    "args.num_inter_threads=56 # <Tune this to get best performance anywhere from 1 to # of physical cores>\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=args.num_threads,\n",
    "                            inter_op_parallelism_threads=args.num_inter_threads)\n",
    "sess = tf.Session(config=config)\n",
    "K.backend.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bulk of the training section can be broken down in 4 simple steps:\n",
    "1. Load the training data\n",
    "1. Define the model\n",
    "3. Train the model on the data\n",
    "4. Evaluate the best model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Loading the datafrom the `HDF5` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filename = os.path.join(args.data_path, args.data_filename)\n",
    "print (\"Full path to the HFS file:\", hdf5_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train, msks_train, imgs_validation, msks_validation, imgs_testing, msks_testing = \\\n",
    "    load_data(hdf5_filename, args.batch_size,[args.crop_dim, args.crop_dim])\n",
    "\n",
    "np.random.seed(816)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 30)\n",
    "print(\"Creating and compiling model ...\")\n",
    "print(\"-\" * 30)\n",
    "unet_model = unet()\n",
    "model = unet_model.create_model(imgs_train.shape, msks_train.shape)\n",
    "\n",
    "model_filename, model_callbacks = unet_model.get_callbacks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Train the model on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The default EPOCH is 30. For testing purpose, this script trains the small BraTs dataset with 3 epochs.\n",
    "\n",
    "To train the unet model realistically, comment the `args.epoch=3` line, or change the epoch anywhere between 20 to 30 while running on the large dataset. It is recommended to run this experiment on a high end Intel Xeon processor if you want to use the large BraTs dataset with 30 epochs, also, make sure to have a large memory space. ETA for the training job on the large BraTs dataset might be 6+ hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 30)\n",
    "print(\"Fitting model with training data ...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"Step 3, training the model started at {}\".format(datetime.datetime.now()))\n",
    "start_time = time.time()\n",
    "\n",
    "args.epochs=3\n",
    "\n",
    "history = model.fit(imgs_train, msks_train,\n",
    "          batch_size=args.batch_size,\n",
    "          epochs=args.epochs,\n",
    "          validation_data=(imgs_validation, msks_validation),\n",
    "          verbose=1, shuffle=\"batch\",\n",
    "          callbacks=model_callbacks)\n",
    "\n",
    "print(\"Total time elapsed for training = {} seconds\".format(time.time() - start_time))\n",
    "print(\"Training finished at {}\".format(datetime.datetime.now()))\n",
    "    \n",
    "# Append training log\n",
    "# with open(\"training.log\",\"a+\") as fp:\n",
    "#     fp.write(\"{}: {}\\n\".format(datetime.datetime.now(),\n",
    "#                              history.history[\"val_dice_coef\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 30)\n",
    "print(\"Loading the best trained model ...\")\n",
    "print(\"-\" * 30)\n",
    "unet_model.evaluate_model(model_filename, imgs_testing, msks_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End: In this tutorial, you have learnt:\n",
    "* What is the U-Net model\n",
    "* How to tweak a series of environment variables to get better performance out of MKLDNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. SPDX-License-Identifier: EPL-2.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Copyright (c) 2019 Intel Corporation`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
